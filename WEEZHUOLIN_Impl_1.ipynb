{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cae1c99",
   "metadata": {},
   "source": [
    "Task: Predict the closing stock price of NASDAQ: NVDA for trading days from 25 October - 7\n",
    "November (inclusive). There will be no restrictions on the data sources used (e.g. you may use\n",
    "relevant macro-economic indicators). Predictions will be compared with actual (after 7 November,\n",
    "but you have to submit before 24 October) using RMSE. The lower the RMSE, the more accurate\n",
    "the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7a5e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas numpy scikit-learn tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62fbb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bd4bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file containing historical price of NVDA from https://finance.yahoo.com/quote/NVDA/history?p=NVDA\n",
    "nvda_data = pd.read_csv('NVDA.csv')\n",
    "nvda_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143243b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "nvda_data['Date'] = pd.to_datetime(nvda_data['Date'])\n",
    "nvda_data.set_index('Date', inplace=True)\n",
    "nvda_data = nvda_data[['Close']]\n",
    "\n",
    "#Data cleaning\n",
    "nvda_data = nvda_data.dropna()\n",
    "\n",
    "nvda_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8faf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting into train and test datasets\n",
    "# Define training and test periods\n",
    "train_end_date = \"2023-10-10\"\n",
    "test_start_date = \"2023-10-11\"\n",
    "\n",
    "# Split the data\n",
    "train_data = nvda_data[nvda_data.index <= train_end_date]\n",
    "test_data = nvda_data[(nvda_data.index >= test_start_date) & (nvda_data.index <= \"2023-10-23\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4456b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature scaling step\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3194dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(data, sequence_length):\n",
    "    X, y = [], []\n",
    "    for i in range(sequence_length, len(data)):\n",
    "        X.append(data[i - sequence_length:i, :])\n",
    "        y.append(data[i, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Define the sequence length\n",
    "sequence_length = 7\n",
    "\n",
    "# Prepare sequences\n",
    "X_train, y_train = prepare_sequences(train_data_scaled, sequence_length)\n",
    "X_test, y_test = prepare_sequences(test_data_scaled, sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fa4fc3",
   "metadata": {},
   "source": [
    "I have chosen to use the LSTM (Long Short-Term Memory) model to predict the closing stock price, as stock prices are a type of sequential data, and LSTM is known for its ability to handle time series data effectively and capture long-term dependencies. In stock markets, historical events and trends can have lasting effects on stock prices, and LSTMs can model these dependencies effectively. SVMs are not very good for time series forecasting because they may not effectively capture temporal dependencies in the data, which are often crucial in stock price prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f45d09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Build the LSTM model\n",
    "model = tf.keras.Sequential([\n",
    "    LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    LSTM(units=50, return_sequences=False),\n",
    "    Dense(units=1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64320d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform the scaled predictions\n",
    "y_pred = scaler.inverse_transform(y_pred)\n",
    "\n",
    "# Extract the corresponding test data for y_true (avoid using slice)\n",
    "y_true = test_data.values[sequence_length:, 0]\n",
    "\n",
    "# Calculate RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
